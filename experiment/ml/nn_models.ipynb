{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from imblearn import over_sampling\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the model on : cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Executing the model on :\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = pd.read_csv(os.path.join('..', '..', 'data', 'tidy_Stroke_Vital_Sign.csv'))\n",
    "\n",
    "ex_data['admission_date'] = ex_data['admission_date'].astype(int).astype(str)\n",
    "in_date = pd.to_datetime(ex_data['admission_date'], format='%Y/%m/%d', errors='coerce')\n",
    "\n",
    "\n",
    "ex_data['discharge_date'] = ex_data['discharge_date'].astype(int).astype(str)\n",
    "out_date = pd.to_datetime(ex_data['discharge_date'], format='%Y/%m/%d', errors='coerce')\n",
    "\n",
    "day_diff = out_date - in_date\n",
    "ex_data['duration'] = day_diff.dt.days\n",
    "\n",
    "y_data = ex_data[['SurvivalWeeks']]\n",
    "X_data = ex_data.drop(['UID', 'Hospital_ID', 'admission_date', 'discharge_date',\n",
    "                       'Mortality', 'CVDeath', 'death_date', 'SurvivalWeeks'], axis=1)\n",
    "\n",
    "categorical_columns = ['Sex', 'AF', 'DM', 'HTN', 'CHF', 'Smoking', 'Cancer before adm']\n",
    "numerical_columns = np.setdiff1d(X_data.columns, categorical_columns)\n",
    "\n",
    "# one-hot\n",
    "X_data_one_hot = pd.get_dummies(X_data, columns=categorical_columns)\n",
    "y_data_od = (y_data < 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN (nn.Module):\n",
    "    def __init__(self, input_len):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_len, 15)\n",
    "        self.fc2 = nn.Linear(15, 7)\n",
    "        self.fc3 = nn.Linear(7, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "lr = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with vital sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n",
      "auc 0.9257180650037793\n",
      "training complete\n",
      "auc 0.9412294598204579\n",
      "training complete\n",
      "auc 0.904089969947408\n",
      "training complete\n",
      "auc 0.9728652784879313\n",
      "training complete\n",
      "auc 0.9785633107340204\n",
      "training complete\n",
      "auc 0.975155458314141\n",
      "training complete\n",
      "auc 0.9705636826204485\n",
      "training complete\n",
      "auc 0.9503148021639186\n",
      "training complete\n",
      "auc 0.9613567388605325\n",
      "training complete\n",
      "auc 0.9431409576532064\n",
      "0.9522997723605844 0.023004006083111244\n"
     ]
    }
   ],
   "source": [
    "model = DNN(input_len=X_data_one_hot.shape[1]).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "all_auroc = []\n",
    "for train_index, test_index in KFold(n_splits=10, random_state=42, shuffle=True).split(X_data_one_hot):\n",
    "    X_train, X_test = X_data_one_hot.iloc[train_index], X_data_one_hot.iloc[test_index]\n",
    "    y_train, y_test = y_data_od.iloc[train_index], y_data_od.iloc[test_index]\n",
    "\n",
    "    # scaling\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # over-sampling\n",
    "    # print('before', y_train.groupby(['SurvivalWeeks']).size())\n",
    "    sm = over_sampling.SVMSMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    # print('after', y_train.groupby(['SurvivalWeeks']).size())\n",
    "\n",
    "    # DataLoader\n",
    "    train_xt = torch.from_numpy(X_train.astype(np.float32)).cuda(device)\n",
    "    train_yt = torch.from_numpy(y_train.values.astype(np.float32)).cuda(device)\n",
    "    train_data = Data.TensorDataset(train_xt, train_yt)\n",
    "    train_loader = Data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_xt = torch.from_numpy(X_test.astype(np.float32)).cuda(device)\n",
    "    test_yt = torch.from_numpy(y_test.values.astype(np.float32)).cuda(device)\n",
    "\n",
    "    train_loss_all = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for step, (inputs, labels) in enumerate(train_loader):\n",
    "            output = model(inputs)\n",
    "            train_loss = loss_function(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_all.append(train_loss.item())\n",
    "#         print(\"train epoch %d, loss %s:\" % (epoch + 1, train_loss.item()))\n",
    "    print('training complete')\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = model(test_xt).cpu().data.numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    print('auc', auroc)\n",
    "    all_auroc.append(auroc)\n",
    "    # plt.figure()\n",
    "    # plt.plot(train_loss_all, \"g-\")\n",
    "    # plt.title(\"DNN: Train loss per iteration\")\n",
    "    # plt.show()\n",
    "print(np.mean(all_auroc), np.std(all_auroc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with vital sign / without ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n",
      "auc 0.9126417233560091\n",
      "training complete\n",
      "auc 0.9374708787624638\n",
      "training complete\n",
      "auc 0.9375469571750563\n",
      "training complete\n",
      "auc 0.9784720630498792\n",
      "training complete\n",
      "auc 0.967002390563154\n",
      "training complete\n",
      "auc 0.9666052510363887\n",
      "training complete\n",
      "auc 0.964521386547941\n",
      "training complete\n",
      "auc 0.937851959897343\n",
      "training complete\n",
      "auc 0.9591150503517726\n",
      "training complete\n",
      "auc 0.9523501565046434\n",
      "0.9513577817244651 0.018739768465919644\n"
     ]
    }
   ],
   "source": [
    "X_data_one_hot_no_icu = X_data_one_hot.drop('ICU', axis=1)\n",
    "\n",
    "model = DNN(input_len=X_data_one_hot_no_icu.shape[1]).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "all_auroc = []\n",
    "for train_index, test_index in KFold(n_splits=10, random_state=42, shuffle=True).split(X_data_one_hot_no_icu):\n",
    "    X_train, X_test = X_data_one_hot_no_icu.iloc[train_index], X_data_one_hot_no_icu.iloc[test_index]\n",
    "    y_train, y_test = y_data_od.iloc[train_index], y_data_od.iloc[test_index]\n",
    "\n",
    "    # scaling\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # over-sampling\n",
    "    # print('before', y_train.groupby(['SurvivalWeeks']).size())\n",
    "    sm = over_sampling.SVMSMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    # print('after', y_train.groupby(['SurvivalWeeks']).size())\n",
    "\n",
    "    # DataLoader\n",
    "    train_xt = torch.from_numpy(X_train.astype(np.float32)).cuda(device)\n",
    "    train_yt = torch.from_numpy(y_train.values.astype(np.float32)).cuda(device)\n",
    "    train_data = Data.TensorDataset(train_xt, train_yt)\n",
    "    train_loader = Data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_xt = torch.from_numpy(X_test.astype(np.float32)).cuda(device)\n",
    "    test_yt = torch.from_numpy(y_test.values.astype(np.float32)).cuda(device)\n",
    "\n",
    "    train_loss_all = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for step, (inputs, labels) in enumerate(train_loader):\n",
    "            output = model(inputs)\n",
    "            train_loss = loss_function(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_all.append(train_loss.item())\n",
    "#         print(\"train epoch %d, loss %s:\" % (epoch + 1, train_loss.item()))\n",
    "    print('training complete')\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = model(test_xt).cpu().data.numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    print('auc', auroc)\n",
    "    all_auroc.append(auroc)\n",
    "    # plt.figure()\n",
    "    # plt.plot(train_loss_all, \"g-\")\n",
    "    # plt.title(\"DNN: Train loss per iteration\")\n",
    "    # plt.show()\n",
    "print(np.mean(all_auroc), np.std(all_auroc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without vital sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n",
      "auc 0.9377739984882841\n",
      "training complete\n",
      "auc 0.9244400956729725\n",
      "training complete\n",
      "auc 0.9169562359128475\n",
      "training complete\n",
      "auc 0.9740818449494861\n",
      "training complete\n",
      "auc 0.9725673080691304\n",
      "training complete\n",
      "auc 0.9713553661906955\n",
      "training complete\n",
      "auc 0.9578828112577517\n",
      "training complete\n",
      "auc 0.9320175033695832\n",
      "training complete\n",
      "auc 0.9743412884535798\n",
      "training complete\n",
      "auc 0.9638357865328401\n",
      "0.952525223889717 0.021320443560194764\n"
     ]
    }
   ],
   "source": [
    "X_data_one_hot_no_vital = X_data_one_hot.drop(['Mean HR', 'MeanHR G', 'HR SD', 'HRSD G', 'HR CV', 'HRCV G', 'Mean SBP',\n",
    "                                               'Mean SBP G', 'SBP SD', 'SBPSD G', 'SBP CV', 'SBPCV G', 'Mean DBP',\n",
    "                                               'MeanDBP G', 'DBP SD', 'DBPSD G', 'DBP CV', 'DBPCV G', 'Mean RR',\n",
    "                                               'MeanRR G', 'RR SD', 'RRSD G', 'RR CV'], axis=1)\n",
    "\n",
    "model = DNN(input_len=X_data_one_hot_no_vital.shape[1]).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "all_auroc = []\n",
    "for train_index, test_index in KFold(n_splits=10, random_state=42, shuffle=True).split(X_data_one_hot_no_vital):\n",
    "    X_train, X_test = X_data_one_hot_no_vital.iloc[train_index], X_data_one_hot_no_vital.iloc[test_index]\n",
    "    y_train, y_test = y_data_od.iloc[train_index], y_data_od.iloc[test_index]\n",
    "\n",
    "    # scaling\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # over-sampling\n",
    "    # print('before', y_train.groupby(['SurvivalWeeks']).size())\n",
    "    sm = over_sampling.SVMSMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    # print('after', y_train.groupby(['SurvivalWeeks']).size())\n",
    "\n",
    "    # DataLoader\n",
    "    train_xt = torch.from_numpy(X_train.astype(np.float32)).cuda(device)\n",
    "    train_yt = torch.from_numpy(y_train.values.astype(np.float32)).cuda(device)\n",
    "    train_data = Data.TensorDataset(train_xt, train_yt)\n",
    "    train_loader = Data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_xt = torch.from_numpy(X_test.astype(np.float32)).cuda(device)\n",
    "    test_yt = torch.from_numpy(y_test.values.astype(np.float32)).cuda(device)\n",
    "\n",
    "    train_loss_all = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for step, (inputs, labels) in enumerate(train_loader):\n",
    "            output = model(inputs)\n",
    "            train_loss = loss_function(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_all.append(train_loss.item())\n",
    "#         print(\"train epoch %d, loss %s:\" % (epoch + 1, train_loss.item()))\n",
    "    print('training complete')\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = model(test_xt).cpu().data.numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    print('auc', auroc)\n",
    "    all_auroc.append(auroc)\n",
    "    # plt.figure()\n",
    "    # plt.plot(train_loss_all, \"g-\")\n",
    "    # plt.title(\"DNN: Train loss per iteration\")\n",
    "    # plt.show()\n",
    "print(np.mean(all_auroc), np.std(all_auroc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only vital sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n",
      "auc 0.8748866213151927\n",
      "training complete\n",
      "auc 0.907215854378281\n",
      "training complete\n",
      "auc 0.8727695341848234\n",
      "training complete\n",
      "auc 0.9245023537916321\n",
      "training complete\n",
      "auc 0.8365795352118196\n",
      "training complete\n",
      "auc 0.8733302625518194\n",
      "training complete\n",
      "auc 0.8815391954205756\n",
      "training complete\n",
      "auc 0.9184837798415834\n",
      "training complete\n",
      "auc 0.8700682852807283\n",
      "training complete\n",
      "auc 0.8383216493778618\n",
      "0.8797697071354318 0.02836895241864546\n"
     ]
    }
   ],
   "source": [
    "X_data_one_hot_only_vital = X_data_one_hot[['Mean HR', 'MeanHR G', 'HR SD', 'HRSD G', 'HR CV', 'HRCV G', 'Mean SBP',\n",
    "                                       'Mean SBP G', 'SBP SD', 'SBPSD G', 'SBP CV', 'SBPCV G', 'Mean DBP',\n",
    "                                       'MeanDBP G', 'DBP SD', 'DBPSD G', 'DBP CV', 'DBPCV G', 'Mean RR',\n",
    "                                       'MeanRR G', 'RR SD', 'RRSD G', 'RR CV']]\n",
    "\n",
    "model = DNN(input_len=X_data_one_hot_only_vital.shape[1]).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "all_auroc = []\n",
    "for train_index, test_index in KFold(n_splits=10, random_state=42, shuffle=True).split(X_data_one_hot_only_vital):\n",
    "    X_train, X_test = X_data_one_hot_only_vital.iloc[train_index], X_data_one_hot_only_vital.iloc[test_index]\n",
    "    y_train, y_test = y_data_od.iloc[train_index], y_data_od.iloc[test_index]\n",
    "\n",
    "    # scaling\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # over-sampling\n",
    "    # print('before', y_train.groupby(['SurvivalWeeks']).size())\n",
    "    sm = over_sampling.SVMSMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    # print('after', y_train.groupby(['SurvivalWeeks']).size())\n",
    "\n",
    "    # DataLoader\n",
    "    train_xt = torch.from_numpy(X_train.astype(np.float32)).cuda(device)\n",
    "    train_yt = torch.from_numpy(y_train.values.astype(np.float32)).cuda(device)\n",
    "    train_data = Data.TensorDataset(train_xt, train_yt)\n",
    "    train_loader = Data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_xt = torch.from_numpy(X_test.astype(np.float32)).cuda(device)\n",
    "    test_yt = torch.from_numpy(y_test.values.astype(np.float32)).cuda(device)\n",
    "\n",
    "    train_loss_all = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for step, (inputs, labels) in enumerate(train_loader):\n",
    "            output = model(inputs)\n",
    "            train_loss = loss_function(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_all.append(train_loss.item())\n",
    "#         print(\"train epoch %d, loss %s:\" % (epoch + 1, train_loss.item()))\n",
    "    print('training complete')\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = model(test_xt).cpu().data.numpy()\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    print('auc', auroc)\n",
    "    all_auroc.append(auroc)\n",
    "    # plt.figure()\n",
    "    # plt.plot(train_loss_all, \"g-\")\n",
    "    # plt.title(\"DNN: Train loss per iteration\")\n",
    "    # plt.show()\n",
    "print(np.mean(all_auroc), np.std(all_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
